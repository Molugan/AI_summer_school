{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD2 : Classification d'image\n",
    "\n",
    "Dans ce TD nous verrons comment utiliser un réseau de neurones convolutifs déjà entrainé pour faire une prédiction sur une image et comment en interpréter les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Commençons par charger un modèle pré-entrainé\n",
    "# Si vous lancez cette commande pour la première fois dans pytorch le téléchargement peut être un peu long\n",
    "import torch\n",
    "\n",
    "# Nous allons charger squeezeNet. Un réseau très léger avec des performances très acceptables sur ImageNet.\n",
    "squeeze_model = torch.hub.load('pytorch/vision:v0.4.2', 'squeezenet1_0', pretrained=True)\n",
    "\n",
    "# Nous n'allons pas entrainer de modèle dans ce TD. Voilà pourquoi il est important de mettre votre modèle en\n",
    "# mode évaluation\n",
    "squeeze_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Net est une collection de 14 millions images couvrant 1000 catégories d'objets ou d'animaux différents. Cette base de données sert de référence pour pré-entrainer des modèles en vision par ordinateur. Un modèle entrainé sur Image Net apprendra donc à différencier des objets de l'une de ces catégories. \n",
    "\n",
    "Mais mille témoignages ne valent pas un regard, testons ensemble.\n",
    "\n",
    "Tout d'abord, récupérons des fonctions pré-définies pour charger et faire apparaître une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import load_image_in_vgg_format, show_image_from_path\n",
    "show_image_from_path('isha.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À tout moment dans le TD vous pourrez ainsi visualiser des images en appelant show_image_from_path(). \n",
    "Essayez par exemple avec 'requin_blanc.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici : afficher 'requin_blanc.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction load_image_in_vgg_format permet de charger une image et de la mettre dans un format directement utilisable par un réseau convolutif. Regardez l'exemple ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load_image_in_vgg_format('isha.jpg')\n",
    "print(x.size())\n",
    "\n",
    "# Que remarquez vous sur la dimension de X ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le vecteur x a le format suivant: taille du batch x Nombre de canaux x hauteur x largeur .\n",
    "\n",
    "Ici on n'a chargé qu'une image donc taille du batch =1. \n",
    "\n",
    "De plus il s'agit d'une image RVB donc: Nombre de canaux =3.\n",
    "\n",
    "**Nous parlerons un peu plus bas de ce format NxCxHxL.**\n",
    "\n",
    "Regardez à présent les valeurs du tensor x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour un meilleur apperçu de ce qui ce passe, vous pouvez jeter un oeil à load_image_in_vgg_format dans tools/tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# À présent appliquons le model à notre image\n",
    "squeeze_net_output = squeeze_model(x)\n",
    "\n",
    "# Regardez un peu les valeurs de vgg_output\n",
    "print(squeeze_net_output)\n",
    "print(squeeze_net_output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit de 1000 scores de sortie, un pour chaque catégorie possible dans Image Net. Ce score en question peut prendre n'importe quelle valeur, positive ou non. **La catégorie avec le score le plus haut correspond à la prédiction du modèle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mais de quel score et quelle catégorie s'agit-il ?\n",
    "print(squeeze_net_output.max())\n",
    "print(squeeze_net_output.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici donc deux valeurs qui ne servent pas à grand chose: que veut dire ce score ?\n",
    "À quelle catégorie correspond ce nombre ?\n",
    "\n",
    "Commençons par le score. Afin de transformer le score de sortie d'un réseau de neurones en une estimation de\n",
    "certiture, on calcule généralement un softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule l'exponentielle terme à terme de la sortie\n",
    "exp_squeeze_net_output = torch.exp(squeeze_net_output)\n",
    "\n",
    "# On normalise le résultat de manière à ce que la somme des scores sur toutes les catégories valent 1.\n",
    "softmax_squeeze_net = exp_squeeze_net_output / exp_squeeze_net_output.sum(dim=1, keepdim=True)\n",
    "\n",
    "# Regardons à présent le score de probabilité de la meilleure prédiction\n",
    "print(softmax_squeeze_net.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch possède un module permettant de faire cette opération\n",
    "pytorch_softmax = torch.nn.functional.softmax(vgg_output, dim=1)\n",
    "\n",
    "# Différence relative entre les deux méthodes\n",
    "# Vous remarquerez que le résultat n'est pas 0 mais un nombre très proche de 0 (différences d'arrondi)\n",
    "print(torch.norm(softmax_squeeze_net - pytorch_softmax) / torch.norm(pytorch_softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'index, regardez dans tools/image_net_2_human.txt pour regarder à quel catégorie correspond la prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1:\n",
    "Écrivez une fonction run_squeeze_net qui étant donné une image dans le bon format, renvoie la certitude de la prédiction telle que définie plus haut ainsi que l'index de la catégorie correspondante.\n",
    "\n",
    "Testez cette fonction avec les images 'isha.jpg', 'requin_blanc.jpg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_squeeze_net(image):\n",
    "    r\"\"\"\n",
    "    Applique le réseau squeeze_model à l'image d'entrée en renvoie le score ainsi que la certitude de la prédiction\n",
    "    correspondante.\n",
    "    Argument:\n",
    "        image: un tenseur de taille 1 x 3 x 224 x 224\n",
    "    Renvoie:\n",
    "        index, certitude où\n",
    "        index (int): est l'index de la catégorie de la prédiction de squeezeNet associée\n",
    "        certitude (float): est la valeur de certitude (calculée avec softmax) correspondant à cette même prédiction\n",
    "    \"\"\"\n",
    "    # Votre code ici !!!\n",
    "    return index, certitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testez votre code ici\n",
    "image_input = load_image_in_vgg_format('isha.jpg')\n",
    "index, certitude = run_squeeze_net(image_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fonction de tools permet d'interpréter directement le vecteur résultat de squeeze_net: il s'agit de Image_net_label_matcher. Comparer les résultats de run_squeeze_net avec les prédictions de Image_net_label_matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import Image_net_label_matcher\n",
    "image_tensor = load_image_in_vgg_format('isha.jpg')\n",
    "squeeze_net_output = squeeze_model(image_tensor)\n",
    "show_image_from_path('isha.jpg')\n",
    "print(Image_net_label_matcher(squeeze_net_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mais pourquoi ce format NxCxHxL ?\n",
    "\n",
    "Pourquoi raisonne-t-on en batchs ? C'est tout simplement parce qu'un réseau de neurones travaille normalement avec plusieurs images à la fois. Regardez l'exemple ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tout d'abord chargeons trois images différentes\n",
    "image_0 = load_image_in_vgg_format('manul.jpg')\n",
    "image_1 = load_image_in_vgg_format('isha.jpg')\n",
    "image_2 = load_image_in_vgg_format('requin_blanc.jpg')\n",
    "\n",
    "# Chaque image a le format suivant : 1 x 3 x 224 x 224\n",
    "# La fonction torch.cat permet de concatener plusieurs vecteurs en un seul\n",
    "batch = torch.cat([image_0, image_1, image_2], dim=0)\n",
    "\n",
    "# Ainsi nous aurons:\n",
    "# batch.size() = 3 x 3 x 224 x 224\n",
    "# batch[0] = image_0\n",
    "# batch[1] = image_1\n",
    "# batch[2] = image_2\n",
    "\n",
    "# Lançons à présent squeezeNet sur le batch\n",
    "output_batch = squeeze_model(batch)\n",
    "\n",
    "# Que remarquez vous sur la taille du batch de sortie ?\n",
    "print(output_batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction Image_net_label_matcher marche sur des batchs de plusieurs images. Regardez l'exemple ci dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Image_net_label_matcher(output_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2:\n",
    "\n",
    "Définissez une fonction rnn_squeeze_net_on_batch qui prend en entrée un batch d'images au format N x C x H x L et renvoie deux vecteurs index et predictions de taille N tels que, pour tout n entre 0 et N-1:\n",
    "\n",
    "- index[n] est l'index de la prédiction correspondant à la n-ième image\n",
    "- predictions[n] est le score de la prédiction correspondant à la n-ième image\n",
    "\n",
    "Indice: si vous ajoutez l'argument dim dans l'operation max() alors pytorch calculera à la fois la valeur maximum maximum et l'index de la valeur maximum selon la dimension donnée.\n",
    "\n",
    "Exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3, 4)\n",
    "max_x_dim1, index_max_x_dim1 = x.max(dim=1)\n",
    "print(x)\n",
    "print(max_x_dim1.size())\n",
    "\n",
    "# max_x_dim1[i, k] = max_j(x[i, j, k])\n",
    "# index_max_x_dim1[i, k] = argmax_j(x[i, j, k])\n",
    "\n",
    "# Exemple\n",
    "# Affiche x[0, i, 2] pour i entre 0 et 3\n",
    "print(\"x:\", x[0, :, 2])\n",
    "\n",
    "print(\"max_x\", max_x_dim1[0, 2])\n",
    "print(\"argmax_x\", index_max_x_dim1[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_squeeze_net_in_batch(image_batch):\n",
    "    r\"\"\"\n",
    "    Applique le réseau squeeze_model au batch d'images d'entréę en renvoie les scores ainsi que les certitudes\n",
    "    des prédictions correspondantes.\n",
    "    Argument:\n",
    "        image: un tenseur de taille N x 3 x 224 x 224\n",
    "    Renvoie:\n",
    "        index (torch.tensor): tensor des index des catégories des prédictions vgg associées \n",
    "                            au batch image_batch. Il doit être de taille N. \n",
    "        certitude (torch.tensor): valeur des certitudes (calculées avec softmax) correspondant \n",
    "                                  à ces même prédictions. Ce tensor doit être de taille N\n",
    "    \"\"\"\n",
    "    # Votre code ici !!!\n",
    "    return index, certitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testez votre code ici:\n",
    "image_0 = load_image_in_vgg_format('manul.jpg')\n",
    "image_1 = load_image_in_vgg_format('isha.jpg')\n",
    "image_2 = load_image_in_vgg_format('requin_blanc.jpg')\n",
    "image_batch = torch.cat([image_0, image_1, image_2], dim=0)\n",
    "index, certitude = run_squeeze_net_in_batch(image_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3: \n",
    "À présent allons plus loin, un réseau peut hésiter. Ne cherchons plus le score de la prédiction la plus probable, mais celui des k prédictions les plus probables (k > 1).\n",
    "\n",
    "Définissez une fonction extrait_les_k_meilleurs qui étant donné le vector squeeze_net_output calculé avec squeeze_net et un entier k, estime les k prédictions les plus probables avec leurs scores respectifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_best_predictions(squeeze_net_output, k):\n",
    "    r\"\"\"\n",
    "    Arguments\n",
    "    1) squeeze_net_output : un batch de taille N x 1000 où N est le nombre d'images dans le batch\n",
    "    2) k (int): le nombre de prédictions aà trouver\n",
    "    \n",
    "    Renvoie:\n",
    "    index, scores\n",
    "    index (torch.tensor): un tensor de taille N x k tel que index[n][k] soit l'index de la k-eme prediction pour\n",
    "                          la n-eme image\n",
    "    score (torch.tensor): un tensor de taille N x k tel que score[n][k] soit le score de la k-eme prediction pour\n",
    "                          la n-eme image\n",
    "    \"\"\"\n",
    "    # Votre code ici\n",
    "    return index, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testez votre code ici:\n",
    "image_0 = load_image_in_vgg_format('manul.jpg')\n",
    "image_1 = load_image_in_vgg_format('isha.jpg')\n",
    "image_2 = load_image_in_vgg_format('requin_blanc.jpg')\n",
    "image_batch = torch.cat([image_0, image_1, image_2], dim=0)\n",
    "index, certitude = get_k_best_predictions(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
