{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD3 : SqueezeNet voit-il les lémuriens ?\n",
    "\n",
    "Dans ce TD nous explorerons les couches de convolutions de SqueezeNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch\n",
    "\n",
    "# Etape 1: charger SqueezeNet\n",
    "squeeze_model = torch.hub.load('pytorch/vision:v0.4.2', 'squeezenet1_0', pretrained=True)\n",
    "\n",
    "# Nous n'allons pas entrainer de modèle dans ce TD. Voilà pourquoi il est important de mettre votre modèle en\n",
    "# mode évaluation\n",
    "squeeze_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons le contenu de squeeze_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(squeeze_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une image traitée par SqueezeNet passera par dans l'ordre par:\n",
    "- 1) squeeze_model.features : ces couches servent à calculer les descripteurs de l'image\n",
    "- 3) squeeze_model.classifier : il s'agit de la partie classification en temps que telle\n",
    "\n",
    "Nous ne nous intéresserons aujourd'hui qu'à squeeze_model.features.\n",
    "\n",
    "## squeeze_model.features\n",
    "\n",
    "Le module Sequential applique dans l'ordre les différent modules qui le compose. \n",
    "\n",
    "Par exemple:\n",
    "\n",
    "Sequential(\n",
    "\n",
    "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (1): ReLU(inplace=True)\n",
    "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (3): ReLU(inplace=True)\n",
    "    \n",
    ")\n",
    "    \n",
    "Est un réseau de neurones qui applique dans l'ordre: une convolution, une fonction d'activation ReLU, une autre convolution et encore un ReLU.\n",
    "\n",
    "La fonction ReLU est définie ainsi: ReLU(x) = max(x, 0).\n",
    "\n",
    "SqueezeNet est une séquence de modules \"Fire\". Un module Fire est la concaténation de deux convolution avec un noyau de taille 1 et une fonction d'activation ReLU, suivies par une convolution avec un noyau 3x3.\n",
    "\n",
    "\n",
    "## Exercice 1:\n",
    "\n",
    "Combien de canaux doit avoir l'image d'entrée donnée à squeeze_models ? Combien de canaux a l'image de sortie de la première convolution du module Fire (5) de SqueezeNet ?\n",
    "\n",
    "squeeze_model.features contient aussi des couches dites \"MaxPool2d\". MaxPool2d ce n'est pas vraiment une convolution mais presque. MaxPool2d réduit la taille de l'image d'entrée en remplaçant chaque fenêtre de l'image de taille choisie k par le maximum des éléments repérés au sein de cette fenêtre.\n",
    "\n",
    "Plus précisément, quand un Maxpool2d de kernel_size k et de stride s est appliqué sur un batch d'images X de dimension $(N, C, sH, sL)$, alors sa sortie est un batch d'images Y de taille $(N, C, H, L)$ tel que:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\text{maxpool2d}(X)(n, c, h, l) = \\max_{0 \\leq \\bar{p} < k, 0 \\leq \\bar{q} < k }X(n, c, h \\times s + \\bar{p}, l \\times s + \\bar{q})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testons MaxPool2d\n",
    "maxPool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "x = torch.randn(2, 2, 4, 2)\n",
    "y = maxPool(x)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2:\n",
    "Comme dans la partie 0 du TD, nous allons devoir récupérer quelques fonctions pré-définies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import load_image_in_vgg_format, show_images_from_path_list, show_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nn_sequential_output(input_batch, sequence_model, n_layer):\n",
    "    r\"\"\"\n",
    "    Calcule la sortie d'une couche spécifique d'un modèle\n",
    "    Arguments:\n",
    "       input_image (torch.tensor): notre image d'entrée au format N x C x L x H\n",
    "       sequence_model (torch.nn.Sequential): le modèle à appliquer. \n",
    "                                             Ce modèle doit se présenter sous la forme d'une séquence de modules.\n",
    "       n_layer (int): index de la sortie que l'on souhaite récupérer\n",
    "    Renvoie:\n",
    "       l'image de sortie de la couche n_layer de sequence_model\n",
    "    \"\"\"\n",
    "\n",
    "    # Notre image d'entrée a un format N x C x H x L\n",
    "    x = input_batch\n",
    "    for i in range(n_layer+1):\n",
    "        x = sequence_model[i](x)\n",
    "\n",
    "    # Notre image de sortie a à présent un format\n",
    "    # N x C_sortie x H_sortie x L_sortie\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testons un peu cette fonction\n",
    "# 1) Chargeons des images\n",
    "\n",
    "show_images_from_path_list(['isha.jpg', 'manul.jpg'])\n",
    "image_isha = load_image_in_vgg_format('isha.jpg')\n",
    "image_manul = load_image_in_vgg_format('manul.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Lançons le modèle\n",
    "batch_data = torch.cat([image_isha, image_manul], dim=0)\n",
    "output_1 = get_nn_sequential_output(batch_data, squeeze_model.features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L'image de sortie a 128 canaux\n",
    "print(output_1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichons à présent l'image correspondant au canal 0 du batch\n",
    "show_batch(output_1[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le constater, le résultat n'est pas très lisible. Pour changer ça définisser \n",
    "une fonction normalize_min_max, qui étant donné un tensor X de forme arbitraire lui applique une transformation\n",
    "affine qui place sa plus petite valeur à zéro et sa plus grande valeur à 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_min_max(input_batch):\n",
    "    r\"\"\"\n",
    "    Applique une transformation affine au tensor input_batch de manière à ce que ses valeurs soient\n",
    "    comprises entre 0 et 1\n",
    "    \"\"\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez ensuite la fonction avec le code suivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensionne les valeurs de output_8 dans [0,1]\n",
    "normalized_output = normalize_min_max(output_1)\n",
    "    \n",
    "# Applique un facteur 255 de manière à avoir des valeurs entre 0 et 255\n",
    "normalized_output = 255 * normalized_output\n",
    "\n",
    "# Affiche l'image correspondant au canal désiré. Dans notre cas nous affichons le canal 0.\\\n",
    "show_batch(normalized_output[:, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'image rendue est toujours assez sombre: c'est normal la plupart des neurones ne sont en réalité que \n",
    "# peu ou pas activés. Pour un rendu plus lisible, vous pouvez augmenter le contraste de l'image en y appliquant\n",
    "# un facteur multiplicatif f\n",
    "\n",
    "# Dans les couches les plus élevées il arrive qu'aucun des neurones d'un canal entier ne soit activé.\n",
    "# Pour pouvoir percevoir la distinction entre les canaux porteurs d'informations sur l'image et les autres\n",
    "# il est nécessaire d'utiliser le même facteur multiplicatif pour comparer l'activité de deux canaux différents\n",
    "normalized_output = 5 * 255 * normalize_min_max(output_1)\n",
    "show_batch(normalized_output[:, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention cependant, un facteur trop élevé saturera l'image.\n",
    "normalized_output = 50 * 255 * normalize_min_max(output_1)\n",
    "show_batch(normalized_output[:, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N'hésitez pas à jouer avec ce script pour visualiser les différents canaux des différentes couches de vgg16 !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : lemur breafeast club\n",
    "\n",
    "Dans le dossier team_lemur vous trouverez une série d'images. Effectuez les tâches suivantes:\n",
    "\n",
    "1) Avec show_images_from_path_list affichez les photos d'origine.\n",
    "\n",
    "2) Chargez toutes les images dans un même batch\n",
    "\n",
    "3) Appliquez get_nn_sequential_output pour obtenir les résultats du 12eme module Fire de squeeze_model.features\n",
    "\n",
    "4) Visualisez les images correspondants au 32eme canal du vecteur sortant. Quel est le motif détecté au niveau de ce canal ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "# À vous de jouer !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
