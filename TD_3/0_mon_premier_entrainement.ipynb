{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD 3 : Entrainer un réseau de neurones basique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classe de base pour tout réseau de neurones dans pytorch est [torch.nn.module](https://pytorch.org/docs/stable/nn.html). Quand vous définissez un réseau de neurones, ce dernier doit hériter de la classe torch.nn.module. Notez qu'un module peut contenir d'autres modules.\n",
    "\n",
    "Quand vous créer un nouveau modèle, vous devez lui définir une fonction forward qui déterminera les opeérations effectives faites par le modèle.\n",
    "\n",
    "Nous allons définir ici un petit réseau de neurones destiné à reconnaitre les chiffres de 1 à 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Nous définissons une classe MonReseau qui hérite de torch.nn.module\n",
    "class MonReseau(torch.nn.Module):\n",
    "    \n",
    "    # En python, __init__ est le constructeur de la classe\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Lorsque l'on crée un module, il faut toujours commencer par initialiser la classe torch.nn.module\n",
    "        super(MonReseau, self).__init__()\n",
    "        \n",
    "        # Notre modéla possédera 5 modules\n",
    "        self.conv1 = torch.nn.Conv2d(1, 4, 4)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv2d(4, 4, 4)\n",
    "        self.pool = torch.nn.MaxPool2d(2)\n",
    "        self.classifier = torch.nn.Linear(64, 10)\n",
    "        \n",
    "    # Un module doit toujours définir une fonction forward\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x) # Applique la premiere convolution\n",
    "        x = self.relu(x)  # Applique la fonction relu\n",
    "        x = self.pool(x)  # Reduit la taille de l'image\n",
    "        x = self.conv2(x) # Applique la deuxieme convolution\n",
    "        x = self.relu(x)  # Applique la fonction relu\n",
    "        x = self.pool(x)  # Reduit la taille de l'image\n",
    "        \n",
    "        # torch.nn.Linear ne prend que les images dans un certain format\n",
    "        N, C, H, L = x.size()\n",
    "        x = x.view(N, -1)\n",
    "        \n",
    "        return self.classifier(x)         # Renvoie le resultat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme la dernière fois, il nous faudra importer des fonctions pré-définies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import MNIST_dataset, show_elem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser le dataset MNIST. MNIST est un petit dataset contenant des chiffres manuscrits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous avons besoin de deux datasets: un dataset d'entrainement et un de validation\n",
    "test_dataset = MNIST_dataset(torch.load('MNIST/processed/test.pt'))\n",
    "train_dataset = MNIST_dataset(torch.load('MNIST/processed/training.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montrons ci-dessous quelques exemples d'images que l'on trouve dans MNIST. Chaque image est associé avec un label qui indique son contenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_0, label_0 = test_dataset[0]\n",
    "item_52, label_52 = test_dataset[52]\n",
    "print(label_0)\n",
    "show_elem(item_0)\n",
    "\n",
    "print(label_52)\n",
    "show_elem(item_52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1:\n",
    "\n",
    "Chercher la taille d'une image typique de MNIST. Par exemple la taille de l'image 48 du test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2: entrainons un réseau\n",
    "\n",
    "Vous allez à présent entrainer votre tout premier réseau de neurones ! Ce dernier sera entrainé sur MNIST: il apprendra donc à reconnaitre des chiffres manuscrits.\n",
    "\n",
    "Commençons tout d'abord par créer une instance du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: NE PAS RELANCER CETTE CELLULE APRES AVOIR EFFECTUE L'ENTRAINEMENT. Vous perdriez tout !\n",
    "mon_reseau = MonReseau()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mon_reseau est un réseau de neurones qui prend en entrée une image noir et blanc de taille 28x28 et renvoie un vecteur de score de taille 10. Voyez plutôt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fabriquons une image aléatoire et passons là dans mon_reseau\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "score_x = mon_reseau(x)\n",
    "print(score_x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite nous avons besoin de mettre les datasets dans des DataLoader. En pytorch le DataLoader a deux fonctions:\n",
    "\n",
    "1) Regrouper les images du dataset en batch de plusieurs images\n",
    "\n",
    "2) Mélanger ces batchs et les donner dans un ordre aléatoire\n",
    "\n",
    "Fabriquons le DataLoader du dataset d'entrainement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les arguments pour construire un data-loader sont les suivants:\n",
    "\n",
    "1) dataset que l'on souhaite charger\n",
    "\n",
    "2) batch_size : taille de chaque batch. Dans l'exemple chaque batch contidendra 4 images\n",
    "\n",
    "3) shuffle: True si les batchs doivent être mélangés\n",
    "\n",
    "De la même manière, créez test_loader, le DataLoader de la base de validation. Mais cette fois-ci, donnez lui un batch_size de 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À présent il nous faut une loss. On utilisera la cross entropy. Dans pytorch, la classe torch.nn.CrossEntropyLoss() combine en un seul module à la fois le softmax et la cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mode = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir, nous avons besoin d'un optimizer. En pytorch l'optimizer est la classe qui utilise les gradients déjà calculés après la rétro-propagation pour mettre à jour les poids du réseau de neurones.\n",
    "\n",
    "Nous prenons un SGD (Stochastic Gradient Descent) qui correspond à une descente de gradient classique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(mon_reseau.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre lr que vous pouvez voir s'appelle le **learning rate**: il correspond à la taille du pas fait lors de la descente de gradient. Plus le **learning rate** est élevé, plus le réseau apprend vite, mais plus ses performances à la convergence seront approximatives.\n",
    "\n",
    "Nous pouvons à présent entrainer le réseau ! Ça va prendre un peu de temps (environ 5min selon les machines), c'est normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous parcourir 3 fois le dataset d'entrainement, on dit que l'on fait 3 epochs\n",
    "for epoch in range(3):\n",
    "    avg_loss_train = 0\n",
    "    n_steps_train = 0\n",
    "    \n",
    "    # Phase d'entrainement\n",
    "    # Nous mettons le réseau en mode train()\n",
    "    mon_reseau.train()\n",
    "    \n",
    "    # On parcourt le dataset d'entrainement\n",
    "    for data, label in train_loader:\n",
    "\n",
    "        # On commence par remettre tous les gradients à zéro\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Puis on calcule le vecteur de score du réseau\n",
    "        score = mon_reseau(data)\n",
    "        \n",
    "        # On compare ce vecteur score avec les labels des images pour obetnir une loss\n",
    "        loss = loss_mode(score, label)\n",
    "        \n",
    "        # À partir de la loss on fait la rétropropagation du gradient.\n",
    "        # Pytorch devine tout seul les gradients à calculer ! Pas besoin de les lui dire.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Maintenant que les gradients sont calculés on peut mettre à jour les paramètres du model\n",
    "        # Cette opération se fait sur l'optimizer avec .step()\n",
    "        optimizer.step()\n",
    "\n",
    "        # On met à jour la loss moyenne calculée lors de l'entrainment pour avoir une idée de ce qu'il se\n",
    "        # passe\n",
    "        avg_loss_train = avg_loss_train + loss\n",
    "        n_steps_train = n_steps_train + 1\n",
    "        \n",
    "    print(f\"Epoch {epoch} loss train = {avg_loss_train / n_steps_train}\")\n",
    "    \n",
    "    # Phase de test\n",
    "    # Nous mettons le réseau en mode eval()\n",
    "    mon_reseau.eval()\n",
    "    \n",
    "    avg_loss_test = 0\n",
    "    n_steps_test = 0\n",
    "    \n",
    "    for data, label in test_loader:\n",
    "        \n",
    "        # Ici pas de gradient: nous voulons juste calculer la loss et la précision du modèle\n",
    "        score = mon_reseau(data)\n",
    "        loss = loss_mode(score, label)\n",
    "        avg_loss_test= avg_loss_test + loss\n",
    "        n_steps_test =n_steps_test +1\n",
    "        \n",
    "    print(f\"Epoch {epoch} loss test = {avg_loss_test / n_steps_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous aimerions savoir si le réseau a appris quelque chose. Faisons un test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test_3, label_test_3 = test_dataset[3] \n",
    "image_test_4, label_test_4 = test_dataset[4] \n",
    "image_test_25, label_test_25 = test_dataset[25]\n",
    "show_elem(image_test_3)\n",
    "show_elem(image_test_4)\n",
    "show_elem(image_test_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met les image_test dans un format lisible pour le réseau\n",
    "image_test_3 = image_test_3.view(1, 1, 28, 28)\n",
    "image_test_4 = image_test_4.view(1, 1, 28, 28)\n",
    "image_test_25 = image_test_25.view(1, 1, 28, 28)\n",
    "\n",
    "# On les concatene en batch\n",
    "batch_test = torch.cat([image_test_3, image_test_4, image_test_25], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Calculez score_test le vecteur de score de batch_test donné par mon_reseau()\n",
    "\n",
    "2) Calculez index_test, certitude_test l'index et la certitudes des predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre Code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3:\n",
    "\n",
    "Trois exemples ce n'est **pas suffisant** pour savoir si un réseau marche ou non. Pour le savoir, il faut calculer le taux d'erreur sur l'ensemble du dataset de test.\n",
    "\n",
    "La fonction ci-dessous calcule le taux d'erreur sur un batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rate(model, input_batch, input_label):\n",
    "    r\"\"\"\n",
    "    Calcule le taux d'erreur du modèle donné sur le batch donné.\n",
    "    Arguments:\n",
    "    model : le model à appliquer\n",
    "    input_batch : un batch d'images au format N x C x H x L\n",
    "    input_label : un tensor de labels au format N\n",
    "    \"\"\"\n",
    "    # On calcule le vecteur de score\n",
    "    # Score est de taille N x10\n",
    "    scores = model(input_batch)\n",
    "    \n",
    "    # On cherche l'element du réseau\n",
    "    # max_index est de taille N\n",
    "    max_score, max_index = scores.max(dim=1)\n",
    "    \n",
    "    N = max_index.size(0)\n",
    "    \n",
    "    # On regarde toutes les fois ou le score maximal ne correspond pas au label\n",
    "    #print(max_index, input_label)\n",
    "    is_false =  max_index != input_label\n",
    "    \n",
    "    # On retourne le taux d'erreur:\n",
    "    return is_false.sum() / float(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la fonction get_error_rate pour calculer le taux d'erreur moyen sur l'ensemble du dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
